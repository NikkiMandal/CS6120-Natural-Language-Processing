{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Classification, some n-gram math and tf-idf\n",
    "\n",
    "Due date: Jan 29th, 2024, 11:59 PM\n",
    "\n",
    "Agenda\n",
    "------\n",
    "+ Detecting the end of a sentence\n",
    "    - Rule-based classifier\n",
    "+ Detecting the sentiment of a sentence\n",
    "    - Rule-based classifier (counting words)\n",
    "    - Measuring Accuracy, Precision, Recall (evaluating a classifier)\n",
    "+ N-gram Math \n",
    "+ tf-idf\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification can take several forms. Here are some vocabulary terms to get you started:\n",
    "\n",
    "- __classifier__: a model that takes data (text, in NLP) as input and outputs a category\n",
    "- __binary classification__: a model that takes input and outputs *one of two* categories (e.g. \"positive\" or \"negative\")\n",
    "- __multinomial classification__: a model that takes input and outputs *one of many* categories (e.g. \"positive\", \"neutral\" or \"negative\" or a language model that chooses one token from the entire vocabulary)\n",
    "\n",
    "\n",
    "- __rule-based classifier__: a classifier that functions based on rules that humans come up with (e.g. \"the end of a sentence is when there is a \".\" \")\n",
    "- __statistical classifier__: a classifier that functions based on counts (statistics) that it has gathered or based on running an algorithm to automatically train parameters on a given data set. \n",
    "    \n",
    "In this lab, you'll be building rule-based classifiers and evaluating them. We'll learn about our first statistical classifier next lecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 0: Who is in your group?\n",
    "\n",
    "__Ashutosh Rane__\n",
    "\n",
    "__Sanjana J D__\n",
    "\n",
    "__Nikita Mandal__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Tokenizer\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fill', 'me', 'in', 'with', 'whatever', 'you', 'want.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def tokenize(s: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenize a string based on whitespace\n",
    "    Parameters:\n",
    "        s - string piece of text\n",
    "    returns a list of strings from the text. \n",
    "    Each item is an individual linguistic unit. \n",
    "    \"\"\"\n",
    "    # TODO: fill in this function\n",
    "    # you may find using the str.split() functions\n",
    "    # helpful\n",
    "    # you may make whatever decisions make sense to you/your \n",
    "    # group about how to tokenize.\n",
    "    # don't spend longer than ~5 minutes implementing this function.\n",
    "    return s.split()\n",
    "\n",
    "test_string = \"fill me in with whatever you want.\"\n",
    "tokenized = tokenize(test_string)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What decisions does your tokenizer make about what should/should not be a token? __It separates the tokens based on white space only.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The Project Gutenberg EBook of Moby Dick; or The Whale, by Herman\n",
      "\n",
      "1238243\n"
     ]
    }
   ],
   "source": [
    "# read in the text of moby dick (ensure the txt file is in the same directory as this notebook)\n",
    "# if you do not already have - link to download text http://www.gutenberg.org/files/2701/2701-0.txt \n",
    "# right click and 'save as' into the directory this notebook is located as 'moby_dick.txt'\n",
    "moby = open('mobydick.txt', \"r\", encoding='utf-8')\n",
    "\n",
    "print(moby.readline()) # first line is blank\n",
    "print(moby.readline()) # second line just to see if its correct\n",
    "moby.close()\n",
    "\n",
    "# now read in the full contents\n",
    "moby = open('mobydick.txt', \"r\", encoding='utf-8')\n",
    "contents = moby.read()\n",
    "moby.close()\n",
    "\n",
    "print(len(contents)) # how long is this string?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 215829\n",
      "Vocabulary length: 33584\n"
     ]
    }
   ],
   "source": [
    "# call your tokenize function on the contents of moby dick\n",
    "tokens = tokenize(contents)\n",
    "print(\"Number of tokens:\",len(tokens))\n",
    "print(\"Vocabulary length:\",len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many tokens are in *Moby Dick* when you use your `tokenize` function on its contents? __215829__\n",
    "3. How big is the __vocabulary__ of *Moby Dick* when you use your `tokenize` function on its contents? __33584__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Detecting the end of a sentence\n",
    "\n",
    "\n",
    "A classifier is, in essence, a function that takes some data $x$ and assigns some label $y$ to it. For a binary classifier, we can model this a function that takes a data point $x$ and returns either `True` or `False`.\n",
    "\n",
    "Later in this class we'll learn about how to build classifiers that automatically learn how to do this, but we'll start where NLP startedâ€”writing some rule-based classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence_end(text: str, target_index: int) -> bool: \n",
    "    \"\"\"\n",
    "    Classify whether or not a *location* is the end of a sentence within\n",
    "    a given text\n",
    "    Parameters:\n",
    "        text - string piece of text\n",
    "        target_index - int candidate location\n",
    "    returns true if the target index is the end of a sentence. \n",
    "    False otherwise. \n",
    "    \"\"\"\n",
    "    # TODO: write a simple, rule-based classifier that\n",
    "    # decides whether or not a specific location is the \n",
    "    # end of a sentence\n",
    "    if text[target_index] == (\".\" or \"?\" or \"!\"):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    # pass \n",
    "\n",
    "# look at the code in the cell below to see example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stocks were up as advancing issues outpaced declining issues on the NYSE by 1.\n",
      "****\n",
      "5 to 1.\n",
      "****\n",
      " Large- and small-cap stocks were both strong, while the S.\n",
      "****\n",
      "&P.\n",
      "****\n",
      " 500 index gained 0.\n",
      "****\n",
      "46% to finish at 2,457.\n",
      "****\n",
      "59.\n",
      "****\n",
      " Among individual stocks, the two top percentage gainers in the S.\n",
      "****\n",
      "&P.\n",
      "****\n",
      " 500 were Incyte Corporation and Gilead Sciences Inc.\n",
      "****\n",
      "\n",
      "total number of sentences: 10\n"
     ]
    }
   ],
   "source": [
    "# example text\n",
    "# feel free to go through different examples\n",
    "\n",
    "# This is the given example text\n",
    "\"\"\"Stocks were up as advancing issues outpaced declining issues \n",
    "          on the NYSE by 1.5 to 1. Large- and small-cap stocks were both strong, \n",
    "          while the S.&P. 500 index gained 0.46% to finish at 2,457.59. Among \n",
    "          individual stocks, the two top percentage gainers in the S.&P. 500 \n",
    "          were Incyte Corporation and Gilead Sciences Inc.\"\"\"\n",
    "\n",
    "example = \"Stocks were up as advancing issues outpaced declining issues on the NYSE by 1.5 to 1. Large- and small-cap stocks were both strong, while the S.&P. 500 index gained 0.46% to finish at 2,457.59. Among individual stocks, the two top percentage gainers in the S.&P. 500 were Incyte Corporation and Gilead Sciences Inc.\"\n",
    "\n",
    "# this code will go through and\n",
    "# build up a string based on the sentence\n",
    "# decisions that your classifier comes up with\n",
    "# it will put \"****\" between the sentences\n",
    "# you do not need to modify any code here\n",
    "so_far = \"\"\n",
    "sentence_count = 0\n",
    "for index in range(len(example)):\n",
    "    # see how the classify_sentence_end function is called!\n",
    "    result = classify_sentence_end(example, index)\n",
    "    so_far += example[index]\n",
    "    if result:\n",
    "        sentence_count += 1\n",
    "        print(so_far)\n",
    "        print(\"****\")\n",
    "        so_far = \"\"\n",
    "        \n",
    "print(so_far)\n",
    "print(\"total number of sentences:\", sentence_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How many sentences are detected using your end of sentence classifier? **10**\n",
    "2. Where did your end of sentence classifier make a mistake? **It counted the decimal points or the periods that are used as abbreviations also as sentence endings.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: install `nltk`\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you finish the first two tasks, work on making sure that you have `nltk` downloaded and accessible to your jupyter notebooks. While you will not be allowed to use `nltk` for most of your homework, we will use it frequently in class to demonstrate tools. \n",
    "\n",
    "[`nltk`](https://www.nltk.org/) (natural language toolkit) is a python package that comes with many useful implementations of NLP tools and datasets.\n",
    "\n",
    "From the command line, using pip: `pip3 install nltk` or `pip install nltk`\n",
    "\n",
    "[installing nltk](https://www.nltk.org/install.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ashra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "# for the tokenizers that we're going to use\n",
    "# won't cause an error if you've already downloaded it\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N.K', '.', 'Jemison', 'is', 'a', 'science', 'fiction', 'author', '.', 'Prof.', 'Felix', 'is', \"n't\", '.']\n"
     ]
    }
   ],
   "source": [
    "example = \"N.K. Jemison is a science fiction author. Prof. Felix isn't.\"\n",
    "words = nltk.word_tokenize(example)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22257\n"
     ]
    }
   ],
   "source": [
    "moby_nltk_tokens = nltk.word_tokenize(contents)\n",
    "# feel free to add/edit code\n",
    "# print(moby_nltk_tokens)\n",
    "print(len(set(moby_nltk_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. How does the size of the vocabulary for Moby Dick compare when you use `nltk`'s tokenizer vs. the one that you made? \n",
    "\n",
    "__The size of the vocabulary decresed for nltk tokenizer compared to the tokenizer that I made. The size of vocabulary for NLTK tokenizer is 22257 whereas for the tokenizer that I made, the length was 33584__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Determining Sentiment\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll use nltk to access the reviews that we want to classify eventually\n",
    "import nltk\n",
    "import nltk.corpus as corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_list(filename):\n",
    "    \"\"\"\n",
    "    Loads a lexicon from a plain text file in the format of one word per line.\n",
    "    Parameters:\n",
    "    filename (str): path to file\n",
    "\n",
    "    Returns:\n",
    "    list: list of words\n",
    "    \"\"\"\n",
    "    with open(filename, 'r', encoding=\"utf-8\") as f:\n",
    "        # skip the header content\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                break\n",
    "        # read the rest of the lines into a list\n",
    "        return [line.strip() for line in f]\n",
    "    # otherwise return an empty list\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postive words length- 2006\n",
      "Negative words length- 4783\n",
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably', 'abominate', 'abomination', 'abort', 'aborted']\n",
      "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable', 'accessible', 'acclaim', 'acclaimed', 'acclamation']\n"
     ]
    }
   ],
   "source": [
    "# load in the positive and negative word lists here\n",
    "# TODO: the paths to your negative/positive word files here\n",
    "neg_lex = load_word_list(\"negative_words.txt\")\n",
    "pos_lex = load_word_list(\"positive_words.txt\")\n",
    "\n",
    "# TODO: How many words are in each list?\n",
    "print(\"Postive words length-\",len(pos_lex))\n",
    "\n",
    "print(\"Negative words length-\",len(neg_lex))\n",
    "\n",
    "\n",
    "# TODO: Use python's list slicing to look at the first 10 elements in each list\n",
    "print(neg_lex[:10])\n",
    "print(pos_lex[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['envious', 'enviously', 'enviousness']\n"
     ]
    }
   ],
   "source": [
    "# TODO: which words are in both the positive and the negative lists?\n",
    "common_words = [common for common in neg_lex if common in pos_lex]\n",
    "print(len(common_words))\n",
    "print(common_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll create our rule-based classifier! We have access to the word lists that you loaded and anything else you know about the world (reflect on how you as a human being can tell if a review is positive/negative). Your classifier need not be perfect, but it should be reasonable (don't just say everything is positive!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_verbose(message, verbose):\n",
    "     if verbose:\n",
    "          print(message)\n",
    "def rule_based_classify(tokens, pos_lexicon, neg_lexicon, verbose = False):\n",
    "    \"\"\"\n",
    "    This function classifies a given tokenized text as positive or negative\n",
    "    based on the provided lexicons.\n",
    "    Parameters:\n",
    "    tokens (list) - list of strings tokenized words in the text to classify\n",
    "    pos_lexicon (list) - list of strings words in the positive word lexicon\n",
    "    neg_lexicon (list) - list of strings words in the negative word lexicon\n",
    "    verbose (boolean) - flag indicating whether or not to print verbose (debugging) output. \n",
    "            Default value False.\n",
    "    Returns:\n",
    "    string \"pos\" if the list of tokens is positive overall, \"neg\" if they are negative overall.\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: implement this function! This is our classifier.\n",
    "    positive_count = 0\n",
    "    negative_count = 0\n",
    "    for token in tokens:\n",
    "        if token in pos_lex:\n",
    "             positive_count += 1\n",
    "        if token in neg_lex:\n",
    "             negative_count += 1\n",
    "    \n",
    "\n",
    "    print_verbose(f\"Postive count {positive_count}\", verbose)\n",
    "    print_verbose(f\"Negative Count {negative_count}\", verbose)\n",
    "    if positive_count >= negative_count:\n",
    "         return \"pos\"\n",
    "    else:\n",
    "         return \"neg\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the happy bastard ' s quick movie review damn that y2k bug . it ' s got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . little do they know the power within . . . going for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . we don ' t know why the crew was really out in the middle of nowhere , we don ' t know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don ' t know why donald sutherland is stumbling around drunkenly throughout . here , it ' s just \" hey , let ' s chase these people around with some robots \" . the acting is below average , even from the likes of curtis . you ' re more likely to get a kick out of her work in halloween h20 . sutherland is wasted and baldwin , well , he ' s acting like a baldwin , of course . the real star here are stan winston ' s robot design , some schnazzy cgi , and the occasional good gore shot , like picking into someone ' s brain . so , if robots and body parts really turn you on , here ' s your movie . otherwise , it ' s pretty much a sunken ship of a movie .\n",
      "here is a film that is so unexpected , so scary , and so original that it caught me off guard and threw me for a loop . okay , it isn ' t quite original , considering it is a sequel to the box office hit species , but it certainly is smart . most films of this genre are reminiscent of those cheesy b - horror films from the 50s and 60s , and some even become them . however , as we learned with the 1995 small - budget horror / sci - fi film , sometimes expectations can be shattered . a lot of criticism has gone against this film ( from what i have read so far , anyway -- yep , all two reviews ) , and it makes me wonder why these types of films are automatically dismissed as gory , laughable pieces of trash . but , the thing is , it isn ' t . it ' s well made , well acted , and quite intelligent . i can see most of the critics now complaining about the level of gore or the level of sexuality in the film . but the species series isn ' t about the lack of these elements . it ' s about how much it can get into one film . and yet , behind it all , it has this basic premise that allows it to get away with doing so . species ii begins in the present day , though it seems to be an alternate universe . many films ( especially sci - fi ones ) create similar timelines as our realistic one , but change it to fit the film ' s needs . species ii begins with the arrival of an american spacecraft , the excursion , landing on the surface of mars . aboard is patrick ross ( justin lazard ) , a very bright and very handsome astronaut . patrick is the son of senator ross ( james cromwell ) , who just wants patrick to succeed . well , it would seem that he has succeeded . landing on the surface of mars , he is the first human being to ever do so . of course , he isn ' t the first ever . about a billion years ago , an alien species supposedly landed on mars and destroyed the perfect living conditions that were able to sustain life . now , of course , the red planet is cold and rocky . no life lives on it . that is , no visible life . patrick , upon leaving the spacecraft and landing on the red soil , collects samples from the ground . he takes them aboard , and puts them in storage . unfortunately , one of the samples contains a form of life , and it gets loose when it is heated aboard the ship . just prior to heading back to earth , this life form creeps along the floor and inhabits the earthlings . they pass out for approximately seven minutes , and then shrug it off as nothing , because they can ' t even remember . they blame it on a technical malfunction . back on earth , patrick begins to have strong urges to mate with as many women as possible . as we know from the original , this is because the alien wants to breed and take over the planet . however , the children that are bred are half - human , as their father is . patrick is really looking for another alien to breed with , and he finds it in eve ( natasha henstridge ) . eve was cloned from dna taken from sil , the original alien . however , this time around , most of her \" alien \" urges have been either decreased dramatically , or lie dormant . the project is led by dr . laura baker ( marg helgenberger , reprising her role from species ) , and her motives seem respectable . since she was involved with the original alien attack , she wants to learn how to stop the alien should it come again . and it has . story - wise , species ii is much stronger than its predecessor , but it is also much stronger than , say , aliens ( hey , i love the film , but you can ' t tell me it was strong on story ) . what surprised me the most with this film was the incorporation of historical facts into the screenplay . in my search for extraterrestrial intelligence course in college , we learned about a piece of rock from mars which landed in one of the poles . this piece of rock contained fossils which may have been proof of life on mars ( later , it was proven that it was not a living creature that created it ) . the script uses this effectively , but also manages to provide a well - balanced plot . beginning with the first man on mars ( something i have always dreamed of seeing ) , i was hoping that the film would turn this element into a useful starting point for the movie . and it does it quite well . the characters are all smart , and they know what to do and what not to do . the only character that seems a little cliched is the general ( george dzundza ) , and yet , he remains logical in everything he does . there are the obvious flaws of course , mostly lying in the technical aspects . the special effects are only mediocre , and some are just plain bad . but for the most part , they remain believable ( i even noticed a homage to the alien series when the mothers gave birth to alien children ) . also , the most realistic ones are usually the goriest , ranging from people being torn open , or someone ' s head being blown off . however , some plot elements also may elicit laughs from the audience , including a menage a troi that is all but necessary . many people dislike the species series because all it is is an excuse for sex , nudity , and gory violence . however , i tend to disagree . what were the alien films about ? and , if an alien species ever did come to earth , and their sole purpose was to destroy us , wouldn ' t you mate as quickly as possible with as many people as possible ? my only gripe with this is during the scene where patrick goes searching for a mate in a grocery store . i didn ' t realize that aliens were that picky on choosing women to mate with ( i just assume it is his part - human side looking for the most beautiful one ) . the acting is quite good for this kind of film . it is a vast improvement over the first film , at least . the acting is the key element to this film : if it was bad , it would have lowered itself into camp ; if it was good , it would have asked for comparison with films like aliens . okay , so it isn ' t that good . george dzundza is probably the most obvious mistake on casting , as his over - the - top impersonation of a general makes him annoying and distracting . natasha henstridge is limited this time around , as she is usually enclosed in a cage . however , she does manage a very impressive performance with this aspect hindering any of her talent . oh yeah , and she ' s quite fun to just plain watch . marg helgenberger is immensely better this time around , and her performance is probably the best in this film . michael madsen is so - so , but he isn ' t annoying , and he soon becomes rather appealing ( with his nice cynic personality ) . james cromwell has a small part , but he makes it much better than what it could have been with a more incapable actor . as i say , any film with james cromwell dramatically increases in likeability . mykelti williamson gives an enjoyable performance , and he gives the film a more down - to - earth feel . and , of course , justin lazard . lazard has so far been ridiculed for his performance , but i think he is effective . sure , he is wooden , but isn ' t that what his character is like ? the moment when he touches the glass separating henstridge from him was extremely well done , due to the couple ' s acting . species ii is rated r for strong sexuality , sci - fi violence / gore and language . this is definitely an r rated film that young kids should not see . more than likely , they would probably have nightmares and never have sex for the rest of their lives . hell , i don ' t even know if i will . what is sure to be a critically lambasted film turns out to be the surprise film of the year . i probably won ' t see another film where i was expecting so little and got so much for quite a while . director peter medak has crafted a very suspenseful , and sometimes very scary movie out of a mediocre series . medak has also mastered the wonderful \" jump ! \" moments , and has probably the second scariest moment i have ever seen on film ( scream still has the first ) . strong acting , smart dialogue , intelligent plotting , and a sure - handed director , species ii is exactly what these films should be : entertaining .\n",
      "Postive count 10\n",
      "Negative Count 6\n",
      "Classification for Negative Tok: pos\n",
      "Classification for Positive Tok: pos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\ashra\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# now, we'll test out your classifier!\n",
    "# Here are two example movie reviews.\n",
    "nltk.download('movie_reviews')\n",
    "movies = corpus.movie_reviews\n",
    "\n",
    "# load in a single negative review\n",
    "negative_toks = movies.words('neg/cv001_19502.txt')\n",
    "# uncomment the text below to see the contents of the review\n",
    "neg_text = \" \".join(negative_toks)\n",
    "print(neg_text)\n",
    "\n",
    "# load in a single positive review\n",
    "positive_toks = movies.words('pos/cv992_11962.txt')\n",
    "pos_text = \" \".join(positive_toks)\n",
    "print(pos_text)\n",
    "\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# call your rule_based_classify on these example reviews.\n",
    "\n",
    "result = rule_based_classify(negative_toks, neg_lexicon = neg_lex, pos_lexicon= pos_lex, verbose = True)\n",
    "print(\"Classification for Negative Tok:\",result)\n",
    "\n",
    "result = rule_based_classify(positive_toks, neg_lexicon = neg_lex, pos_lexicon = pos_lex, verbose = False  )\n",
    "print(\"Classification for Positive Tok:\",result)\n",
    "\n",
    "\n",
    "# Does our classification function label them correctly? Why or why not?\n",
    "# take a look at the contents of the reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What labels does your classifier assign these two reviews? __My Classifier assigns both the test cases as Positive__\n",
    "2. Are these correct? __The First test case is a negative review as the end of the review says \"it ' s pretty much a sunken ship of a movie.\". So my classifier is giving inaccurate classification results.__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: How good is your sentiment classifier?\n",
    "-----\n",
    "\n",
    "Given the movies dataset from `nltk`, how many of the reviews does your classifier classify correctly?\n",
    "\n",
    "We'll look at three different metrics: __accuracy__, __precision__, and __recall__.\n",
    "\n",
    "__accuracy__: what you think of when you think of correctness.\n",
    "$$ \\frac{\\texttt{number correct}}{\\texttt{total number}}$$\n",
    "\n",
    "Precision and recall require differentiated between the ways in which the classifier can be correct or incorrect. \n",
    "\n",
    "- __true positive__: an example whose gold label is positive and that the classifier labels as positive\n",
    "- __true negative__: an example whose gold label is negative and that the classifier labels as negative\n",
    "- __false positive__: an example whose gold label is negative and that the classifier labels as positive\n",
    "- __false negative__: an example whose gold label is positive and that the classifier labels as negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# you can use numpy's random functionality if you'd like to\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "['neg/cv538_28485.txt', 'neg/cv436_20564.txt', 'neg/cv358_11557.txt', 'neg/cv918_27080.txt', 'neg/cv681_9744.txt', 'neg/cv055_8926.txt', 'neg/cv513_7236.txt', 'neg/cv281_24711.txt', 'neg/cv563_18610.txt', 'neg/cv611_2253.txt', 'neg/cv037_19798.txt', 'neg/cv454_21961.txt', 'neg/cv994_13229.txt', 'neg/cv857_17527.txt', 'neg/cv569_26750.txt', 'neg/cv589_12853.txt', 'neg/cv693_19147.txt', 'neg/cv132_5423.txt', 'neg/cv379_23167.txt', 'neg/cv911_21695.txt', 'neg/cv896_17819.txt', 'neg/cv586_8048.txt', 'neg/cv966_28671.txt', 'neg/cv609_25038.txt', 'neg/cv866_29447.txt', 'neg/cv003_12683.txt', 'neg/cv019_16117.txt', 'neg/cv884_15230.txt', 'neg/cv430_18662.txt', 'neg/cv306_10859.txt', 'neg/cv269_23018.txt', 'neg/cv752_25330.txt', 'neg/cv241_24602.txt', 'neg/cv541_28683.txt', 'neg/cv247_14668.txt', 'neg/cv068_14810.txt', 'neg/cv328_10908.txt', 'neg/cv931_18783.txt', 'neg/cv913_29127.txt', 'neg/cv066_11668.txt', 'neg/cv973_10171.txt', 'neg/cv671_5164.txt', 'neg/cv498_9288.txt', 'neg/cv746_10471.txt', 'neg/cv573_29384.txt', 'neg/cv224_18875.txt', 'neg/cv835_20531.txt', 'neg/cv904_25663.txt', 'neg/cv356_26170.txt', 'neg/cv699_7773.txt', 'neg/cv410_25624.txt', 'neg/cv222_18720.txt', 'neg/cv601_24759.txt', 'neg/cv389_9611.txt', 'neg/cv304_28489.txt', 'neg/cv018_21672.txt', 'neg/cv122_7891.txt', 'neg/cv934_20426.txt', 'neg/cv135_12506.txt', 'neg/cv172_12037.txt', 'neg/cv291_26844.txt', 'neg/cv623_16988.txt', 'neg/cv654_19345.txt', 'neg/cv146_19587.txt', 'neg/cv290_11981.txt', 'neg/cv212_10054.txt', 'neg/cv802_28381.txt', 'neg/cv676_22202.txt', 'neg/cv502_10970.txt', 'neg/cv276_17126.txt', 'neg/cv661_25780.txt', 'neg/cv740_13643.txt', 'neg/cv349_15032.txt', 'neg/cv717_17472.txt', 'neg/cv528_11669.txt', 'neg/cv118_28837.txt', 'neg/cv250_26462.txt', 'neg/cv540_3092.txt', 'neg/cv630_10152.txt', 'neg/cv008_29326.txt', 'neg/cv126_28821.txt', 'neg/cv606_17672.txt', 'neg/cv729_10475.txt', 'neg/cv092_27987.txt', 'neg/cv785_23748.txt', 'neg/cv805_21128.txt', 'neg/cv399_28593.txt', 'neg/cv710_23745.txt', 'neg/cv638_29394.txt', 'neg/cv134_23300.txt', 'neg/cv487_11058.txt', 'neg/cv470_17444.txt', 'neg/cv020_9234.txt', 'neg/cv450_8319.txt', 'neg/cv033_25680.txt', 'neg/cv316_5972.txt', 'neg/cv924_29397.txt', 'neg/cv577_28220.txt', 'neg/cv783_14724.txt', 'neg/cv864_3087.txt']\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "# To see the available file ids, this is one way that we can access them.\n",
    "# This will give you a list of neg/positive file ids.\n",
    "print(len(movies.fileids('neg')))\n",
    "# choose 100 random items without replacement from a list\n",
    "print(random.sample(movies.fileids('neg'), 100))\n",
    "print(len(movies.fileids('pos')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Postive: 69\n",
      "False Negative: 31\n",
      "True Negative: 81\n",
      "False Positive: 19\n"
     ]
    }
   ],
   "source": [
    "# TODO:\n",
    "# Write code that uses your classifier to classify 100 randomly chosen\n",
    "# negative reviews and 100 randomly chosen positive reviews\n",
    "# count the number of true positives, true negatives, false positives, and false negatives\n",
    "\n",
    "# to get the tokens associated with a certain file id,\n",
    "# tokens = movies.words(file_id)\n",
    "\n",
    "# takes a long time to run if you loop over all fileids as opposed to just\n",
    "# 100 randomly chosen ones\n",
    "# make sure you don't classify the same review twice!\n",
    "# (it takes us about 10 seconds to classify 200 reviews on a 2020 macbook air)\n",
    "# movies.fileids('neg')\n",
    "random_neg_list = random.sample(movies.fileids('neg'), 100)\n",
    "random_pos_list = random.sample(movies.fileids('pos'), 100)\n",
    "\n",
    "result_pos = [result for result in random_pos_list]\n",
    "\n",
    "result_actual_pos = [rule_based_classify(movies.words(review), neg_lexicon=neg_lex, pos_lexicon=pos_lex, verbose=False) for review in random_pos_list]\n",
    "tp = result_actual_pos.count(\"pos\")\n",
    "fn = result_actual_pos.count(\"neg\")\n",
    "print(\"True Postive:\",tp)\n",
    "print(\"False Negative:\", fn)\n",
    "result_actual_pos = [rule_based_classify(movies.words(review), neg_lexicon=neg_lex, pos_lexicon=pos_lex, verbose=False) for review in random_neg_list]\n",
    "\n",
    "tn = result_actual_pos.count(\"neg\")\n",
    "fp = result_actual_pos.count(\"pos\")\n",
    "print(\"True Negative:\",tn)\n",
    "print(\"False Positive:\",fp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print(random_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "# TODO: print out the number of true positives, false positives,\n",
    "# false negatives, and true negatives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the equations for accuracy, precision, and recall in terms of what we've just been counting. $tp$ means true positive, $fp$ means false positive, $fn$ means false negative, and $tn$ means true negative.\n",
    "\n",
    "$$ accuracy = \\frac{tp + tn}{tp + fp + fn + tn}$$\n",
    "\n",
    "$$ precision = \\frac{tp}{tp + fp}$$\n",
    "\n",
    "$$ recall = \\frac{tp}{tp + fn}$$\n",
    "\n",
    "You can think of precision as \"how many of my positive guesses were correct?\" and recall as \"how many of the positive examples did I find?\" ðŸ˜„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.75\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate and print accuracy\n",
    "accuracy = (tp+tn)/(tp+fp+fn+tn)\n",
    "print(\"Accuracy is:\",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is: 0.78\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate and print precision\n",
    "\n",
    "precision = tp/(tp+fp)\n",
    "print(f\"Precision is: {precision:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall is 0.69\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate and print recall\n",
    "recall = tp/(tp+fn)\n",
    "print(f\"Recall is {recall :.2f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: n-gram math\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That took: 0.03499913215637207 seconds!\n",
      "That took: 0.0 seconds!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import Counter\n",
    "\n",
    "def count_list(ls: list) -> dict:\n",
    "    counts = {}\n",
    "    for item in ls:\n",
    "        # we're not going to be clever about counting here,\n",
    "        # no conditionals, no sets, nothing\n",
    "        counts[item] = ls.count(item)\n",
    "    return counts\n",
    "\n",
    "# see the difference between the following two items\n",
    "example = [random.randint(0, 100) for i in range(2000)]\n",
    "start = time.time()\n",
    "count_list(example)\n",
    "end = time.time()\n",
    "print(\"That took:\", end - start, \"seconds!\")\n",
    "\n",
    "# this takes a very similar amount of time to count_dict from HW 1\n",
    "start = time.time()\n",
    "Counter(example)\n",
    "end = time.time()\n",
    "print(\"That took:\", end - start, \"seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put your create_ngrams (or make_ngrams) function here!\n",
    "def make_ngrams(tokens: list, n: int) -> list:\n",
    "    \"\"\"Creates n-grams for the given token sequence.\n",
    "    Args:\n",
    "    tokens (list): a list of tokens as strings\n",
    "    n (int): the length of n-grams to create\n",
    "\n",
    "    Returns:\n",
    "    list: list of tuples of strings, each tuple being one of the individual n-grams\n",
    "    \"\"\"\n",
    "    # TODO: implement this function!\n",
    "    return [tuple(tokens[i:i+n]) for i in range(len(tokens) - n + 1)]\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final probability: 0.3333333333333333\n",
      "That took 0.0015087127685546875 seconds!\n"
     ]
    }
   ],
   "source": [
    "# TODO: calculate the bigram score of the following sequence of tokens\n",
    "# for this example, we'll use a \"vanilla\" scoring technique\n",
    "# no Laplace smoothing, no unknown tokens\n",
    "training_data = [\"<s>\", \"I\", \"love\", \"dogs\", \"</s>\", \"<s>\", \"I\", \"love\", \"cats\", \"</s>\", \"<s>\", \"I\", \"love\", \"dinosaurs\", \"</s>\"]\n",
    "\n",
    "# TODO: call your create_ngrams function to get your bigrams\n",
    "\n",
    "train_bigrams = make_ngrams(training_data, 2)\n",
    "vocab = count_list(train_bigrams)\n",
    "to_score = [\"<s>\", \"I\", \"love\", \"cats\", \"</s>\"]\n",
    "start = time.time()\n",
    "\n",
    "# BEGIN SCORING SECTION\n",
    "# start probability at one so that we can multiply the probability of\n",
    "# each subsequent next token with it\n",
    "test_bigram = make_ngrams(to_score,2)\n",
    "total_prob = 1\n",
    "for i in range(0, len(test_bigram)):\n",
    "    # TODO: YOUR SCORE CALCULATION CODE HERE\n",
    "    total_prob *= vocab[test_bigram[i]]/training_data.count(to_score[i])\n",
    "\n",
    "# END SCORING SECTION\n",
    "end = time.time()\n",
    "\n",
    "# print your final probability\n",
    "print(\"Final probability:\", total_prob)\n",
    "print(\"That took\", end - start, \"seconds!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training tokens: 56670\n",
      "That took 7.9273340702056885 seconds!\n"
     ]
    }
   ],
   "source": [
    "# Finally, pretend that we had a lot more data\n",
    "training_data = [\"<s>\", \"I\", \"love\", \"dogs\", \"</s>\", \"<s>\", \"I\", \"love\", \"cats\", \"</s>\", \"<s>\", \"I\", \"love\", \"dinosaurs\", \"</s>\"]\n",
    "# this is the amount of training data in the berp set(https://www1.icsi.berkeley.edu/Speech/berp.html)\n",
    "training_data = training_data * 3778\n",
    "\n",
    "# TODO: call your create_ngrams function here\n",
    "train_bigrams2 = make_ngrams(training_data, 2)\n",
    "\n",
    "print(\"Number of training tokens:\", len(training_data))\n",
    "start = time.time()\n",
    "total_prob = 1\n",
    "# and what if we had 5000 sentences to score?\n",
    "for example_num in range(5000):\n",
    "    # TODO: COPY AND PASTE YOUR SCORING CODE HERE (between \"BEGIN SCORING SECTION\" and \"END SCORING SECTION\")\n",
    "    test_bigram = make_ngrams(to_score,2)\n",
    "    total_prob = 1\n",
    "    for i in range(0, len(test_bigram)):\n",
    "    # TODO: YOUR SCORE CALCULATION CODE HERE\n",
    "        total_prob *= vocab[test_bigram[i]]/training_data.count(to_score[i])\n",
    "    # (remove any print statements that you have)\n",
    "    # (make sure it is appropriately indented)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "print(\"That took\", end - start, \"seconds!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's the moral of the story? If you perform your counts at the same time you score, you'll be doing the same work over and over again which will result in a significantly slower model!\n",
    "\n",
    "Make sure that you're gathering the counts that you need in `train` and only performing scoring calculations (as opposed to also counting things) in `score`.\n",
    "\n",
    "This is particularly important when using larger data sets! (berp is not that big)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Calculating tf-idf\n",
    "----\n",
    "\n",
    "Recall our discussion of tf-idf vector representations of documents in a corpus. Here, we will learn how to compute the tf-idf values for each token in a document. To calculate tf-idf, we'll need to first construct a term-document matrix from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf(term: str, document: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate term frequency\n",
    "    Parameters:\n",
    "    term - string\n",
    "    document - list of strings (tokenized document)\n",
    "    Return:\n",
    "    float term frequency\n",
    "    \"\"\"\n",
    "    return np.log10(document.count(term) + 1)\n",
    "\n",
    "def idf(N: int, df_t: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate inverse document frequency given the \n",
    "    number of documents and the number of documents the term appears in.\n",
    "    Paramenters:\n",
    "    N - int (number of documents)\n",
    "    df_t - int (number of documents the term appears in)\n",
    "    Return:\n",
    "    float inverse document frequency\n",
    "    \"\"\"\n",
    "    return np.log10(N / df_t)\n",
    "\n",
    "\n",
    "def term_in_documents(term: str, documents: list) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the number of documents in a list of documents that a target\n",
    "    term appears in.\n",
    "    Parameters:\n",
    "    term - str\n",
    "    documents - list of list of str (list of tokenized documents)\n",
    "    Return:\n",
    "    int number of documents the term appears in\n",
    "    \"\"\"\n",
    "    #TODO: IMPLEMENT ME\n",
    "    count = 0\n",
    "    for doc in documents:\n",
    "        if term in doc:\n",
    "            count+=1\n",
    "\n",
    "    return count\n",
    "\n",
    "\n",
    "# load in the data\n",
    "def load_tokens(filename):\n",
    "    f = open(filename, 'r', encoding=\"utf-8\")\n",
    "    contents = f.read().lower()\n",
    "    f.close()\n",
    "    # if you don't have nltk installed, use another tokenization\n",
    "    # strategy here like str.split()\n",
    "    return nltk.word_tokenize(contents)\n",
    "\n",
    "mobydick = load_tokens('mobydick.txt') \n",
    "shakes = load_tokens('shakespeare.txt')\n",
    "pandp = load_tokens('prideandprejudice.txt')\n",
    "books = [mobydick, shakes, pandp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we won't create the entire term-document matrix, we'll just do it for a few key terms that we\n",
    "# care about for the sake of time\n",
    "# TODO: pick 3 - 5 words\n",
    "words = ['jupiter','beauty','rose','parsley','good']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jupiter :\t 4\t34\t0\n",
      "beauty :\t 8\t228\t26\n",
      "rose :\t 23\t64\t7\n",
      "parsley :\t 1\t1\t0\n",
      "good :\t 195\t2793\t180\n",
      "[[0.12308251 0.27189689 0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.         0.         0.        ]\n",
      " [0.05300875 0.05300875 0.        ]\n",
      " [0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# create the term-document matrix\n",
    "matrix = []\n",
    "\n",
    "# iterate through your chosen words\n",
    "for word in words:\n",
    "    # count how many times it occurs in each book\n",
    "    # this is just for debugging for you\n",
    "    counts = [str(b.count(word)) for b in books]\n",
    "    print(word, \":\\t\", \"\\t\".join(counts))\n",
    "    \n",
    "    \n",
    "    # calculate the term frequency for each book\n",
    "    # for this word\n",
    "    # tf_words should be the same length as counts\n",
    "    tf_words = [tf(word,book) for book in books]\n",
    "\n",
    "    \n",
    "    # calculate idf for this term\n",
    "    # this will be a single scalar\n",
    "    N = len(books)\n",
    "    df_t = term_in_documents(word, books)\n",
    "    idf_t = idf(N,df_t)\n",
    "    \n",
    "    # multiply tf with idf for each book/each\n",
    "    # term frequency you calculated\n",
    "    tfidf_words = [tf_word*idf_t for tf_word in tf_words ]\n",
    "    \n",
    "    # add the tfidf numbers to your matrix\n",
    "    matrix.append(tfidf_words)\n",
    "    \n",
    "    # uncomment to see visually the different components (helpful for debugging)\n",
    "    #print(word, \" tf:\\t\", \"\\t\".join([str(x) for x in tf_words]))\n",
    "    #print(word, \"idf:\\t\", idf_t)\n",
    "    #print(word, \" tf-idf:\\t\", \"\\t\".join([str(x) for x in tfidf_words]))\n",
    "    \n",
    "# if you'd like to, uncomment the following code to make the matrix into a numpy array\n",
    "matrix = np.array(matrix)\n",
    "print(matrix)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. What should the dimensions of your matrix be? \n",
    "\n",
    "__The words list has 5 elements and books has 3, therefore our matrix should be a 5x3 matrix__\n",
    "\n",
    "2. What happens if you attempt to calculate tfidf of a term that exists in none of your books? \n",
    "\n",
    "__If the term does not exist in the books, the code throws Dividing by zero error. Since df_t = 0 and idf = np.log10(N / df_t) will be dividing by 0, hence the error.__\n",
    "\n",
    "2. What happens if you attempt to calculate tfidf of a term that exists in all of your books? \n",
    "\n",
    "__If the term exists in all the books then N = df_t and log(N/df_t) = 0. tfidf will be 0.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3)\n"
     ]
    }
   ],
   "source": [
    "# check the dimensions of your matrix\n",
    "# number of rows should match number of words\n",
    "# number of cols should match number of documents (books)\n",
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity between 'tiger' and 'lion': 0.6719511934699012\n"
     ]
    }
   ],
   "source": [
    "def cosine_sim(v1: list, v2: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity between two vectors of the same length.\n",
    "    Parameters:\n",
    "    v1 - list (of numbers)\n",
    "    v2 - list (of numbers)\n",
    "    Return:\n",
    "    float cosine similarity\n",
    "    \"\"\"\n",
    "    # you may find the numpy functions np.dot() and np.linalg.norm() useful\n",
    "    # TODO: implement\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    \n",
    "    if norm_v1 == 0 or norm_v2 == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    \n",
    "    similarity = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity\n",
    "\n",
    "# calculate the similarity between two word vectors\n",
    "# we'll just do word vectors because unless matrix is a numpy array\n",
    "# it is (more) difficult to get column vectors\n",
    "\n",
    "word_vectors = {\n",
    "    'tiger': np.array([0.2, 0.8, -0.3]),\n",
    "    'lion': np.array([0.9, 0.4, -0.6]),\n",
    "    'cat': np.array([-0.4, 0.3, 0.7])\n",
    "}\n",
    "similarity_tiger_lion = cosine_sim(word_vectors['tiger'], word_vectors['lion'])\n",
    "print(\"Cosine Similarity between 'tiger' and 'lion':\", similarity_tiger_lion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Section (no extra credit)\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you finish, which book is closest to moby dick?\n",
    "# you'll need a *column* vector here (instead of a row vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you finish finish, which book is closest to moby dick, but remake your matrix with all vocabulary terms?\n",
    "# create the term-document matrix\n",
    "# you'll want to use counters for each book's vocabulary for the sake of efficiency\n",
    "\n",
    "\n",
    "# you may want to re-define new counter versions of your tf, idf, term_in_documents \n",
    "# functions so that they work with counters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the shape of your matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which book is actually closest to moby dick?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
